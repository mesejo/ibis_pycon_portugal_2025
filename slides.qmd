---
title: "Unifying Data Management in Python with Ibis"
author:
  - Daniel Mesejo
format: 
  revealjs:
    theme: ["style/light.scss"]
    multiplex: false
    footer: "Unifying Data Management in Python with Ibis"
    slide-number: c/t
    incremental: true
    title-slide-attributes:
      data-background-size: cover  
editor: visual
---

## Who am I

- Daniel, Founding Engineer @ **Xorq Labs**
- Software engineer with a knack for Machine Learning and Data Analytics
- I enjoy sharing knowledge, used to hang on StackOverflow
- Open-Source contributor (ibis, dask, xarray, geopandas, datafusion-python)
- Python Barcelona Organizer
- Curious fact: I lived in Brazil for 5 years


## {.center}

<img class="r-stretch" src="/images/Xorq_WordMark.png" alt="Xorq Labs" style="display: block; margin: 0 auto;"/>

:::{.notes}
At Xorq Labs, we are trying to define an open compute format for AI
:::

## Xorq Labs

<img class="r-stretch" src="/images/xorq_qr.png" alt="Xorq QR" style="display: block; margin: 0 auto;"/>
<p style="display: block; margin: 0 auto; text-align: center;">&#11088; https://github.com/xorq-labs/xorq &#11088;</p> 

:::{.notes}
We have created Xorq a library that takes major inspiration from Ibis, here is a link to the repo, if you could go and give a star if helps pay the bills. Enough with the AD and into the talk.
:::

## Structure of the Talk

- **What & Why Ibis** – introduction and architecture overview 
- **10-min Ibis Demo** – basic Ibis usage and syntax (like pandas!)
- **Case Study: Only Moka** – a fictional coffee marketplace startup

:::{.notes}
Here's our roadmap for today. We'll start with an intro to what Ibis is and why it exists. Then I'll do a quick demo to show you how Ibis looks in code. The core of the talk is a case study from "Only Moka" coffee company, following three team members – a data scientist, a data engineer, and a software engineer – and seeing how Ibis helps them collaborate. Finally, I'll wrap up with key takeaways and leave time for some questions.
:::

## What is Ibis?

- **Ibis** is the Portable Python **DataFrame library**
- Provides a **single pandas-like interface** for nearly 20 SQL/analytics backends 
- Write Python data manipulations once, execute them on **DuckDB, PostgreSQL, BigQuery, Spark**, etc.
- Built on **lazy evaluation** – Ibis builds a query plan and defers execution to the backend engine

:::{.notes}
So what exactly is Ibis? In short, Ibis is a Python library that lets you write data analysis code in one familiar API and run it on many different engines. You can use commands that feel like pandas – filtering, grouping, joining – but under the hood Ibis will translate those operations to whatever backend you choose, whether it's DuckDB locally, a PostgreSQL database, or even big data engines like Spark or BigQuery. The key idea is lazy evaluation: when you write Ibis code, it doesn't do the work immediately. Instead, it builds a query (like an abstract syntax tree) and only executes when needed. This means it can optimize and push the computation to the database or engine, taking advantage of those systems' performance.
:::

## What is Ibis?

<img class="r-stretch" src="/images/backends.png" alt="Ibis backends"/>

:::{.notes}
This is a plot of the many backends Ibis wraps, for the SQL backends it uses SQLGlot and for polars it uses direct Python translation, it used to support pandas, but it was 
deprecated in version 10
:::

## Ibis Architecture

- **Unified expression**: Ibis operations create a backend-agnostic query plan (no data loaded yet)
- **Query compilation**: When executed, Ibis **compiles** your expression into the backend’s native SQL (or API) and runs it there
- **Backend engines**: DuckDB by default for fast local analytics; swap to Postgres, BigQuery, etc. by changing a connection string

:::{.notes}
Let's talk a bit about how Ibis works internally. When you write Ibis code, you're building a **unified expression** of your query. Think of it as an abstract representation of the data transformation you want. Ibis doesn't touch the data immediately; it waits until you tell it to execute (for example, by converting to pandas or calling `.execute()`). At that point, Ibis **compiles** your expression into the native query language of your chosen backend. If you're using DuckDB, it becomes DuckDB SQL; for Spark, it might generate a Spark plan, and so on. 

This architecture is what allows you to **seamlessly move between environments**. You might start on your laptop using DuckDB (which is the default and great for local work), and later switch to a PostgreSQL connection for production. You don't have to rewrite your analysis in SQL – Ibis will generate equivalent SQL for you. And if you're ever curious or need to optimize, you can call `ibis.to_sql()` on an expression to see the SQL string it would run. It's a great way to verify or even share the query with a data engineer as we will see later.
:::

## Ibis Architecture

- **Seamless env switch**: Develop on a local file, then point to prod DB – **no code changes** needed (just a different `ibis.connect`)
- **Transparency**: If needed, use `ibis.to_sql()` to see or reuse the SQL that Ibis generates for your queries

:::{.notes}
This architecture is what allows you to **seamlessly move between environments**. You might start on your laptop using DuckDB (which is the default and great for local work), and later switch to a PostgreSQL connection for production. You don't have to rewrite your analysis in SQL – Ibis will generate equivalent SQL for you. And if you're ever curious or need to optimize, you can call `ibis.to_sql()` on an expression to see the SQL string it would run. It's a great way to verify or even share the query with a DBA if needed.
:::

## {.center}

<h5 class="r-fit-text">DEMO</h5>

## Only Moka 

**Only Moka** – a fictional specialty coffee marketplace with lots of data

### Team roles

- **Ana** – Data Scientist (exploratory analysis in pandas)
- **João** – Data Engineer (production data pipelines in SQL)
- **Maria** – Software Engineer (backend APIs in FastAPI)


## Only Moka Challenge (no Ibis)

Each handoff meant a full rewrite of logic:

- Ana's pandas analysis had to be re-coded by João in SQL for Postgres
- João’s SQL results had to be reimplemented by Maria in Python (or via an ORM) for the API
- This duplication introduced bugs and delays, and feedback loops were slow

:::{.notes}
Now let's move into our case study: Only Moka. It's a (fictional) direct-to-consumer coffee company – think of it as a marketplace and data hub for specialty coffee. They have a lot of data on coffees, roasters, prices, reviews, etc.

The data team at Only Moka has three key players:

Ana, a data scientist who explores data and builds models (she's been using pandas and notebooks).
João, a data engineer who needs to take those insights and implement them in the company’s PostgreSQL data warehouse.
Maria, a software engineer who builds FastAPI endpoints to expose analytics and recommendations to the application.
:::

## Only Moka Solution (Ibis)

Adopt Ibis so all three use the same code – one lingua franca across environments and roles

:::{.notes}
With no Ibis, this workflow was painful. Ana would do an analysis in pandas, but then João essentially had to retranslate that into SQL from scratch to run on Postgres. Every time Ana tweaked her analysis, João had to update the SQL. And when Maria needed to provide those results via an API, she might either call João's SQL or, worse, duplicate some logic in Python again. Each stage was a handoff in a different "language" – Python, then SQL, then back to Python – with lots of opportunity for inconsistencies and bugs. It also meant that if Ana found a new insight, it could take days or weeks before it was reflected in the live product.

Only Moka decided to introduce Ibis as a common layer. With Ibis, Ana, João, and Maria can all work with the same exact code for data transformations. Ana writes it once in Ibis; João can use that to generate SQL or directly execute it in the database; Maria can call the same logic in the API. Let's see how that works in practice for each of them.
:::

## {.center}

<h5 class="r-fit-text">DEMO</h5>


## Ibis vs SQL

When to use SQL:

- Query Optimization
- Highly Secure and Regulated Environments

When to use Ibis:

- Need to switch between different data engines
- Working with both SQL databases and DataFrame-like systems 

:::{.notes}
Before moving to the Key Takeaways I would like to address the Ibis vs SQL problem, in general 

Query Optimization - You want to squeeze every ounce of performance for your query
Highly Secure and Regulated Environments - You work in environment where the data should stay in the database

Switching Between Data Engines - Write once, run anywhere across PostgreSQL, DuckDB.
SQL Databases and DataFrame-like Systems - You need more than SQL systems.
:::

## Key Takeaways

- **Faster iteration loop**
- **Code reuse**
- **SQL when you need it**
- **Environment management** 
- **Fewer bugs, easier maintenance** 

:::{.notes}
To wrap up, I want to emphasize a few key benefits of Ibis:

Seamless environment management: The team could use DuckDB for fast local development and then move to PostgreSQL in staging/production without changing the code. This made it easy to test on small data and then run on the full dataset in prod. Future migrations (say, to BigQuery or Spark) are also much simpler since Ibis supports those backends too.

Code reuse across roles: Perhaps the biggest win – everyone from Ana to João to Maria was using the same definitions. This eliminated the duplicate implementations. They created a shared analytics library (we called it shared_analytics.py) where core logic lived. If Ana improves the recommendation formula, it automatically applies in production and in the API. This also fostered better feedback: Maria and João could contribute to the same code that Ana wrote if they noticed issues, and Ana could easily see how her work was used downstream.

Faster iteration: Because of this reuse, the time from an insight to a live feature shrank dramatically. Something that used to take maybe weeks (with multiple handoffs and rewrites) could be done in a day. For Only Moka, they reported about a 75% reduction in development cycle time for data-driven features, and effectively zero translation bugs because there was no manual translation!

Still get SQL when needed: Ibis doesn't black-box your logic; João was able to compile the SQL for transparency. So they didn't lose the ability to fine-tune queries or use database-specific optimizations – they just didn't have to start from scratch in SQL.

Maintainability: One unified codebase is simply easier to maintain. One set of unit tests can validate the logic across all backends. And there's no ambiguity about "which version of the logic is the source of truth" – it’s the Ibis code.

Overall, Ibis acted as the “data lingua franca” for Only Moka. It bridged the gap between the diverse tools and languages the team used. By adopting Ibis, they unlocked not only performance gains (remember, up to 193x faster analytics in some cases) but also a huge boost in team productivity and confidence in the results.

Thank you for listening, and I'd be happy to take questions or discuss how you might start using Ibis in your own projects!
:::

## {.center}

<h5 class="r-fit-text">Thank You</h5>
<h5 class="r-fit-text">https://github.com/mesejo/ibis_pycon_portugal_2025</h5>